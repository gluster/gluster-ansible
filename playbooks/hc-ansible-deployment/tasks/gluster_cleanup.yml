---
- name: Remove gluster setup
  hosts: hc_nodes
  remote_user: root
  gather_facts: False
  ignore_errors: True
  tasks:

    - name: Stop Gluster volume(s)
      ansible.builtin.expect: 
        command: gluster volume stop {{ item.volname }} force
        responses: 
          (.*)Do you want to continue?(.*): "y"
      run_once: True
      with_items: "{{ gluster_features_hci_volumes }}"
      when: gluster_features_hci_volumes is defined

    - name: Delete Gluster volume(s)
      ansible.builtin.expect: 
        command: gluster volume delete {{ item.volname }}
        responses:
          (.*)Do you want to continue?(.*): "y"
      run_once: True
      with_items: "{{ gluster_features_hci_volumes }}"
      when: gluster_features_hci_volumes is defined
      tags:
        - delete_volumes

    #- name: Delete the volumes
    #  gluster_volume:
    #    state: absent
    #    name: "{{ item.volname }}"
    #  run_once: True
    #  with_items: "{{ gluster_features_hci_volumes }}"
    #  when: gluster_features_hci_volumes is defined
    #  tags:
    #    - delete_volumes

    # Remove the brick directories
    - name: Remove brick directories
      file:
        state: absent
        path: "{{ item.brick }}"
      with_items: "{{ gluster_features_hci_volumes }}"
      when: gluster_features_hci_volumes is defined

    - name: Unmount the disks
      mount:
        state: absent
        path: "{{ item.path }}"
      with_items: "{{ gluster_infra_mount_devices }}"

    - name: Wipe filesystem from LVs
      shell: wipefs -a /dev/{{ item.vgname }}/{{ item.lvname}}
      register: shell_output
      changed_when: shell_output.rc == 0
      failed_when: False
      with_items: "{{ gluster_infra_mount_devices }}"

    - name: Delete volume groups
      command: vgremove {{ item.vgname }} -y
#      lvg:
#        vg: "{{ item.vgname }}"
#        state: absent
#        force: yes
      with_items: "{{ gluster_infra_volume_groups }}"
      when: gluster_infra_volume_groups is defined

    - name: Remove PV
      shell: pvremove {{ item.pvname }} -f
      register: shell_output
      changed_when: shell_output.rc == 0
      with_items: "{{ gluster_infra_volume_groups }}"
      when: gluster_infra_volume_groups is defined
      failed_when: False

    - name: Remove Cache PV
      shell: pvremove {{ item.cachedisk }} -f
      register: shell_output
      changed_when: shell_output.rc == 0
      with_items: "{{ gluster_infra_cache_vars }}"
      when: gluster_infra_cache_vars is defined
      failed_when: False

    # Remove vdo devices if any
    - name: Remove VDO devices
      command: "vdo remove -n {{ item.name }} --force"
      #vdo:
      #  name: "{{ item.name }}"
      #  state: absent
      with_items: "{{ gluster_infra_vdo }}"
      when: gluster_infra_vdo is defined

    - name: Remove ansibleStatus file
      file:
        path: /usr/share/cockpit/ovirt-dashboard/ansible/ansibleStatus.conf
        state: absent

    - name: Get the list of hosts to be detached
      shell: gluster pool list | egrep -vw '(localhost|Hostname)' | awk '{print $2}'
      register: peernodes
      run_once: true

    - name: Delete a node from the trusted storage pool
      command: gluster peer detach {{ item }} --mode=script
      with_items: "{{ cluster_nodes }}"
      when: item != inventory_hostname and peernodes.stdout_lines|length > 0
      run_once: true

    - name: Remove specified device from blacklist
      blockinfile:
        path: /etc/multipath/conf.d/blacklist.conf
        marker: "# {mark} ANSIBLE MANAGED BLOCK {{ item }}"
        content: ""
      with_items: "{{ blacklist_mpath_devices }}"
      when: blacklist_mpath_devices is defined
    
    - name: Wipe devices
      shell: wipefs -a /dev/{{ item }}
      register: shell_output
      changed_when: shell_output.rc == 0
      failed_when: False
      with_items: "{{ blacklist_mpath_devices }}"

    - name: Reload multipathd
      shell: systemctl reload multipathd.service
      failed_when: False
      when: blacklist_mpath_devices is defined

    - name: Restore LVM filter rules generated by vdsm
      shell: >
        vdsm-tool config-lvm-filter -y

  tags:
    - cleanup_bricks
